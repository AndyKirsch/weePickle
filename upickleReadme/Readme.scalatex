
@import Main._


@def lnk(txt: String, url: String) = a(txt, href:=url)
@val exampleTests = wd/'upickle/'test/"src-jvm"/'upickle/'example/"ExampleTests.scala"
@val macroTests = wd/'upickle/'test/'src/'upickle/"MacroTests.scala"

@val optionsAsNullTests =  wd/'upickle/'test/"src-jvm"/'upickle/'example/"OptionsAsNullTests.scala"


@a(
  href := "https://github.com/lihaoyi/upickle-pprint",
  img(
    position.absolute,
    top := 0,
    right := 0,
    border := 0,
    src := "https://camo.githubusercontent.com/365986a132ccd6a44c23a9169022c0b5c890c387/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f7265645f6161303030302e706e67",
    alt := "Fork me on GitHub",
    data.`canonical-src` := "https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
  )
)

@sect("ÂµPickle 0.6.0")

  @p
    uPickle (pronounced micro-pickle) is a lightweight serialization library
    for Scala. It's key features are:
  @ul
    @li
      Less than 1000 lines of code
    @li
      Zero-reflection 100% static serialization and deserialization
    @li
      @sect.ref("Getting Started", "Human-readable JSON encoding"), with a
      fast @sect.ref("uJson", "JSON API")
    @li
      @sect.ref("Supported Types", "A large, well-defined set of supported types, with well-defined semantics")
    @li
      Handling of @sect.ref("Defaults", "default values") and
      @sect.ref("Custom Keys", "custom keys"), for maintaining backwards
      compatiblity while schemas change
    @li
      Minimal dependencies: Only depends on @lnk("Jawn",
      "https://github.com/non/jawn") on the JVM, and on the Javascript
      standard library in Scala.js
    @li
      Works in @sect.ref("ScalaJS"), allowing transfer of structured data
      between the JVM and Javascript

  @sect{Getting Started}
    @p
      Add the following to your SBT config:
    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "upickle" % "0.6.0"


    @p
      And then you can immediately start writing and reading common Scala
      objects to strings:

    @hl.ref(exampleTests, Seq("'simple", ""))

    @sect{ScalaJS}
      @p
        For ScalaJS applications, use this dependencies instead:
      @hl.scala
        libraryDependencies += "com.lihaoyi" %%% "upickle" % "0.6.0"
      @p
        Other than that, everything is used the same way. upickle-0.6.0
        is only compatible with ScalaJS 0.6.x.

    @sect{Scala 2.10}
      @p

        uPickle 0.5.x does not support Scala 2.10; only 2.11 and 2.12 are supported

  @sect{Basics}
    @sect{Builtins}
      @p
        This is a non-comprehensive list of what the most commonly-used types
         pickle to using uPickle. To begin, let's import upickle

      @hl.scala
        import upickle.default._

      @p
        Booleans are serialized as JSON booleans

      @hl.ref(exampleTests, Seq("'more", "'booleans", ""))

      @p
        Numbers are serialized as JSON numbers

      @hl.ref(exampleTests, Seq("'more", "'numbers", ""))

      @p
        Except for @hl.scala{Long}s, which too large for Javascript. These are
        serialized as JSON Strings, keeping the interchange format compatible
         with the browser's own JSON parser, which provides the best
          performance in Scala.js

      @hl.ref(exampleTests, Seq("'more", "'longs", ""))

      @p
        Special values of @hl.scala{Double}s and @hl.scala{Float}s are also
        serialized as Strings

      @hl.ref(exampleTests, Seq("'more", "'specialNumbers", ""))



      @p
        Both @hl.scala{Char}s and @hl.scala{String}s are serialized as Strings

      @hl.ref(exampleTests, Seq("'more", "'charStrings", ""))

      @p
        @code{Array}s and most immutable collections are serialized as JSON lists

      @hl.ref(exampleTests, Seq("'more", "'seqs", ""))

      @p
        @code{Option}s are serialized as JSON lists with 0 or 1 element

      @hl.ref(exampleTests, Seq("'more", "'options", ""))


      @p
        Tuples of all sizes (1-22) are serialized as heterogenous JSON lists

      @hl.ref(exampleTests, Seq("'more", "'tuples", ""))

      @p
        Case classes of sizes 1-22 are serialized as JSON dictionaries with the
        keys being the names of each field.
        To begin with, you need to define a serializer in the Case Class's
        companion object:

      @hl.scala
        import upickle.default.{ReadWriter => RW, macroRW}

      @p
        After that, you can begin serializing that case class.

      @hl.ref(exampleTests, Seq("object Simple", ""))
      @hl.ref(exampleTests, Seq("'more", "'caseClass", ""), "  }")

      @p
        Sealed hierarchies are serialized as tagged values, the serialized
        object tagged with the full name of the instance's class:

      @hl.ref(exampleTests, Seq("object Sealed", ""))
      @hl.ref(exampleTests, Seq("'more", "'sealed", ""), "  }")

      @p
        Serializability is recursive; you can serialize a type only if all
        its members are serializable. That means that collections, tuples and
        case-classes made only of serializable members are themselves serializable

      @hl.ref(exampleTests, Seq("object Recursive", ""))
      @hl.ref(exampleTests, Seq("'more", "'recursive", ""), "  }")

      @p

        Nulls serialize into JSON nulls, as you would expect

      @hl.ref(exampleTests, Seq("'more", "'null", ""), "  }")

      @p
        uPickle only throws exceptions on unpickling; if a pickler is
        properly defined, serializing a data structure to a @hl.scala{String}
        should never throw an exception.

    @sect{Reading & Writing Other Things}

      @p
        Apart from reading & writing `java.lang.String`s, allows you to easily
        read from alternate sources such as `CharSequence`s, `Array[Byte]`s,
        `java.io.File`s and `java.nio.file.Path`s:

      @hl.ref(exampleTests, Seq("'sources", ""), "  }")

      @p
        Reading from large files is automatically streamed so you do not read the
        entire file into memory
    @sect{Defaults}

      @p
        If a field is missing upon deserialization, uPickle uses the default
        value if one exists

      @hl.ref(exampleTests, Seq("'defaults", "'reading"), "  }")

      @p

        If a field at serialization time has the same value as the default,
         uPickle leaves it out of the serialized blob

      @hl.ref(exampleTests, Seq("'defaults", "'writing"), "  }")

      @p

        This allows you to make schema changes gradually, assuming you have
        already pickled some data and want to add new fields to the case classes
        you pickled. Simply give the new fields a default value (e.g.
        @hl.scala{""} for Strings, or wrap it in an @hl.scala{Option[T]} and
        make the default @hl.scala{None}) and uPickle will happily read the
        old data, filling in the missing field using the default value.
    @sect{Supported Types}
      @p
        Out of the box, uPickle supports writing and reading the following types:
      @ul
        @li
          @hl.scala{Boolean}, @code{Byte}, @code{Char}, @code{Short},
          @code{Int}, @code{Long}, @code{Float}, @code{Double}
        @li
          @code{Tuple}s from 1 to 22
        @li
          Immutable @code{Seq}, @code{List}, @code{Vector}, @code{Set},
          @code{SortedSet}, @code{Option}, @code{Array}, @code{Map}s, and all
          other collections with a reasonable @hl.scala{CanBuildFrom} implementation
        @li
          @code{Duration}, @code{Either}
        @li
          Stand-alone @hl.scala{case class}es and @hl.scala{case object}s, and
           their generic equivalents,
        @li
          Non-generic @hl.scala{case class}es and @hl.scala{case object}s that
          are part of a @hl.scala{sealed trait} or @hl.scala{sealed class} hierarchy
        @li
          @hl.scala{sealed trait} and @hl.scala{sealed class}es themselves,
           assuming that all subclasses are picklable
        @li
          @code{UUID}s
        @li
          @hl.scala{null}
      @p
        Readability/writability is recursive: a container such as a @code{Tuple}
        or @hl.scala{case class} is only readable if all its contents are
         readable, and only writable if all its contents are writable. That means
          that you cannot serialize a @hl.scala{List[Any]}, since uPickle doesn't
           provide a generic way of serializing @code{Any}. Case classes are only
           serializable up to 22 fields.

      @p
        Case classes are serialized using the @hl.scala{apply} and
        @hl.scala{unapply} methods on their companion objects. This means that
        you can make your own classes serializable by giving them companions
         @hl.scala{apply} and @hl.scala{unapply}. @hl.scala{sealed} hierarchies
         are serialized as tagged unions: whatever the serialization of the
         actual object, together with the fully-qualified name of its class, so
          the correct class in the sealed hierarchy can be reconstituted later.

      @p
        That concludes the list of supported types. Anything else is not supported.


  @sect{Customization}
    @sect{Custom Picklers}
      @hl.ref(exampleTests, Seq("'mapped", ""), "}")
      @p
        You can use the @code{readwriter[T].bimap[V]} function to create a pickler
        that reads/writes a type @code{V}, using the pickler for type @code{T},
        by providing a conversion function between them.

      @p
        The type you are @code{.bimap}ing to doesn't need to be a case class,
        or be pickleable in any way, as long as the type you are
        @code{.bimap}ing from is pickleable. The following example demonstrates
        using @code{.bimap} to define a serializer for non-case Scala class

      @hl.ref(exampleTests, Seq("object Custom2", ""))

      @p
        Note that when writing custom picklers, it is entirely up to you to get
        it right, e.g. making sure that an object that gets round-trip
        pickled/unpickled comes out the same as when it started.

    @sect{Custom Keys}
      @p

        uPickle allows you to specify the key that a field is serialized with
        via a @hl.scala{@@key} annotation


      @hl.ref(exampleTests, Seq("object Keyed", ""))
      @hl.ref(exampleTests, Seq("'keyed", "'attrs", ""))

      @p

        Practically, this is useful if you want to rename the field within your
        Scala code while still maintaining backwards compatibility with
        previously-pickled objects. Simple rename the field and add a
        @hl.scala{@@key("...")} with the old name so uPickle can continue to work
        with the old objects correctly.
      @p
        You can also use @hl.scala{@@key} to change the name used when pickling
        the case class itself. Normally case classes are pickled without their
        name, but an exception is made for members of sealed hierarchies which
        are tagged with their fully-qualified name. uPickle allows you to use
        @hl.scala{@@key} to override what the class is tagged with:

      @hl.ref(exampleTests, Seq("object KeyedTag", ""))
      @hl.ref(exampleTests, Seq("'keyed", "'tag", ""))



      @p
        This is useful in cases where:
      @ul
        @li
          you wish to rename the class within your Scala code, or move it to a
          different package, but want to preserve backwards compatibility with
          previously pickled instances of that class
        @li
          you try to tackle the resource issue (bandwidth, storage, CPU) because
          FQNs might get quite long

    @sect{Custom Configuration}
      @p
        Often, there will be times that you want to customize something on a
        project-wide level. uPickle provides hooks in letting you subclass the
        @hl.scala{upickle.Api} trait to create your own bundles apart from the
        in-built @hl.scala{upickle.default} and @hl.scala{upickle.legacy}. You
        have multiple levels of possible customization:

      @ul
        @li
          @hl.scala{upickle.Api}, which lets you customize the @hl.scala{annotate}
          methods, which are used to tag sealed hierarchies with their class
          names. This is used to e.g. distinguish @hl.scala{upickle.default}'s
          @hl.scala{$type} attribute vs @hl.scala{upickle.legacy}'s array-wrapper
        @li
          @hl.scala{upickle.AttributeTagged}, which assumes you want the standard
          @hl.scala{annotate} method using a type attribute, but letting you
          customize the attribute.
        @li
          In both these cases, you are also free to override the
          @hl.scala{CaseR} and @hl.scala{CaseW} implicits, which controls how case
          classes are serialized. For example, you could make it serialize to a
          JSON array rather than a dictionary. Or, for example, convert the
          @code{camelCase} Scala identifiers to @code{snake_case} or some other
          convention:

        @hl.ref(exampleTests, Seq("'snakeCase", ""))

      @p
        If you are using uPickle to convert JSON from another source into Scala
        data structures, you may find the following encoding of
        @hl.scala{Option[T]} more convenient than the defaults:

      @hl.ref(optionsAsNullTests, "object OptionPickler", "// end_ex")

      @p
        This custom configuration allows you to treat @hl.scala{null}s as
        @hl.scala{None}s and anything else as @hl.scala{Some(...)}s. Simply
        @hl.scala{import OptionPickler._} instead of the normal uPickle import
        throughout your project and you'll have the customized reading/writing
        available to you.

  @sect{Limitations}

    @p
      uPickle doesn't currently support:
    @ul
      @li
        Circular object graphs
      @li
        Reflective reading and writing
      @li
        Read/writing of untyped values e.g. @code{Any}
      @li
        Read/writing arbitrarily shaped objects
      @li
        Read/writing case classes with multiple parameter lists.
    @p
      Most of these limitations are inherent in the fact that ScalaJS does not
      support reflection, and are unlikely to ever go away. In general, uPickle
      is designed to serialize statically-typed, tree-shaped, immutable data
      structures. Anything more complex is out of scope.

    @sect{Manual Sealed Trait Picklers}
      @p
        Due to a bug in the Scala compiler SI-7046, automatic sealed trait
        pickling can fail unpredictably. This can be worked around by instead
        using the @code{macroRW} and @code{merge} methods to manually specify
        which sub-types of a sealed trait to consider when pickling:
    
      @hl.ref(macroTests, "sealed trait TypedFoo", "// End TypedFoo")

  @sect{uJson}

    @p
      uJson is uPickle's JSON library, which can be used to easily
      manipulate JSON source and data structures without converting them into
      Scala case-classes. This all lives in the @code{ujson} package.

    @p
      You can use @code{ujson} to conveniently construct JSON blobs, either
      programmatically:
    @hl.ref(exampleTests, Seq("'json", "'construction", ""), "}")

    @p
      Or parsing them from strings, byte arrays or files:

    @hl.ref(exampleTests, Seq("'json", "'simple", ""), "}")

    @p
      @code{ujson.Js} ASTs are mutable, and can be modified before being re-serialized
      to strings:

    @hl.ref(exampleTests, Seq("'json", "'mutable", ""), "}")

    @p
      case classes or other Scala data structures can be converted to
      @code{ujson.Js} ASTs using @code{upickle.default.writeJs}, and the
      @code{ujson.Js} ASTs can be converted back using @code{upickle.default.readJs}
      or plain @code{upickle.default.read}:

    @hl.ref(exampleTests, Seq("'json", "'intermediate", ""), "}")

    @p
      If you just need to parse & manipulate some JSON, without converting it
      into Scala data-types first, uJson and @code{ujson.Js} will probably be
      able to do what you need.

    @p
      uJson comes bundled with uPickle, or can be used stand-alone via the
      following package coordinates:

    @hl.scala
      libraryDependencies += "com.lihaoyi" %% "ujson" % "0.6.0"

    @sect{Transformations}
      @p
        uJson allows you seamlessly convert between any of the following forms
        you may find your JSON in:

      @ul
        @li
          Case classes & Scala data-types
        @li
          @code{ujson.Js} ASTs
        @li
          @code{String}s
        @li
          @code{CharSequence}s
        @li
          @code{Array[Byte]}s
        @li
          Third-party JSON ASTs (Argonaut, Circe, Json4s, Play-Json)
      @p
        This is done using the @code{ujson.transform(source, dest)} function:

      @hl.ref(exampleTests, Seq("'json", "'misc", ""), "}")

      @p
        All transformations from A to B using @code{ujson.transform} happen
        in a direct fashion: there are no intermediate JSON ASTs being generated,
        and performance is generally very good.

      @p
        You can use @code{ujson.transform} to validate JSON in a streaming
        fashion:

      @hl.ref(exampleTests, Seq("'json", "'validate", ""), "}")

      @p
        The normal @code{upickle.default.read/write} methods to serialize Scala
        data-types is just shorthand for ujson.transform,
        using a @code{upickle.default.writable(foo)} as the source or a
        @code{upickle.default.reader[Foo]} as the destination:

      @hl.ref(exampleTests, Seq("'json", "'upickleDefault", ""), "}")

    @sect{Other ASTs}
      @p
        uJson does not provide any other utilities are JSON that other libraries
        do: zippers, lenses, combinators, etc.. However, uJson can be used to
        seamlessly convert between the JSON AST of other libraries! This means
        if some other library provides a more convenient API for some kind of
        processing you need to do, you can easily parse to that library's AST,
        do whatever you need, and convert back after.

      @p
        As mentioned earlier, conversions are fast and direct, and happen
        without creating intermediate JSON structures in the process. The
        following examples demonstrate how to use the conversion modules for
        @lnk("Argonaut", "http://argonaut.io/doc/"),
        @lnk("Circe", "https://github.com/circe/circe"),
        @lnk("Json4s", "https://github.com/json4s/json4s"), and
        @lnk("Play Json", "https://github.com/playframework/play-json").
      @p
        Each example parses JSON from a string into that particular library's
        JSON AST, manipulates the AST using that library, un-pickles it into
        Scala data types, then serializes those data types first into that
        library's AST then back to a st.ring

      @sect{Argonaut}
        @b{Maven Coordinates}

        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-argonaut" % "0.6.0"

        @b{Usage}
        @hl.ref(exampleTests, Seq("'argonaut", ""), "}")

      @sect{Circe}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-circe" % "0.6.0"
        @b{Usage}
        @hl.ref(exampleTests, Seq("'circe", ""), "}")

      @sect{Play-Json}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-play" % "0.6.0"
        @b{Usage}
        @hl.ref(exampleTests, Seq("'play", ""), "}")

      @sect{Json4s}
        @b{Maven Coordinates}
        @hl.scala
          libraryDependencies += "com.lihaoyi" %% "ujson-json4s" % "0.6.0"
        @b{Usage}
        @hl.ref(exampleTests, Seq("'json4s", ""), "}")

      @sect{Cross-Library Conversions}
        @p
          uJson lets you convert between third-party ASTs efficiently and with
          minimal overhead: uJson converts one AST to the other directly
          and without any temporary compatibility data structures. The following
          example demonstrates how this is done: we parse a JSON string using
          Circe, perform some transformation, convert it to a Play-Json AST,
          perform more transformations, and finally serialize it back to a
          String and check that both transformations were applied:

        @hl.ref(exampleTests, Seq("'crossAst", ""), "}")

  @sect{Version History}
    @sect{0.5.1}
      @ul
        @li
          Strip out automatic "deep" case-class serialization: you must now
          define a serializer for each case class you want to deal with, preferably
          in the companion object
        @li
          Upgrade Jawn version to 0.11.0, add helpers in @code{ujson} to
          parse JSON coming from files.
        @li
          New @code{ujson.writeTo} function for serializing JSON directly
          to a @code{java.io.Writer}, rather than creating a @code{String}

        @li
          @code{ujson.write} now takes an optional `sortKeys` flag, if
          you want the JSON dictionaries to rendered in a standardized order

        @li
          Drop support fo Scala 2.10
    @sect{0.4.3}
      @ul
        @li
          Support for @hl.scala{BigInt} and @hl.scala{BigDecimal},
          thanks to @lnk("Jisoo Park", "https://github.com/guersam")
        @li
          @code{Js.Value}s are now serializable, thanks to
          @lnk("Felix Dietze", "https://github.com/fdietze")
        @li
          Made it easy to write @sect.ref{Manual Sealed Trait Picklers}
          in order to work around problems with SI-7046
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.2")
    @sect{0.4.1}
      @ul
        @li
          Changes to @lnk("PPrint", "http://www.lihaoyi.com/upickle-pprint/pprint/#0.4.1")
    @sect{0.4.0}
      @ul
        @li
          Allow custom handling for JSON @hl.scala{null}s via a @sect.ref{Custom Configuration}
        @li
          Made @hl.scala{upickle.key} a @hl.scala{case class}
        @li
          Remove unnecessary dependency of @hl.scala{derive} on default arguments #143
        @li
          Fixed derivation allowing Caching Picklers in a @hl.scala{case class}'s companion object, potentially speeding up compilation times and runtimes
    @sect{0.3.9}
      @ul
        @li
          Add @hl.scala{.arr: Seq[Js.Value]}, @hl.scala{.obj: Map[String, Js.Value]}, @hl.scala{.str: String} and @hl.scala{.num: Double} helper methods on @hl.scala{Js.Value} to simplify usage as a simple JSON tree.
        @li
          @hl.scala{Invalid.Json} and @hl.scala{Invalid.Data} now have better exception messages by default, which should simplify debugging
        @li
          Some usages should compile faster due to fiddling with implicits (#138)
    @sect{0.3.8}
      @ul
        @li
          Tweaks to PPrint
    @sect{0.3.7}
      @ul
        @li
          You can now pass in an @hl.scala{indent} parameter to @hl.scala{upickle.default.write} in order to format/indent the JSON nicely across multiple lines
        @li
          Derivation based on sealed abstract classes works, in addition to traits (#104), thanks to @a("Voltir", href:="https://github.com/Voltir")
        @li
          Fix non-deterministic failure due to improperly implemented @code{equals}/@code{hashCode} in macro (#124), thanks to @a("Voltir", href:="https://github.com/lihaoyi/upickle-pprint/issues/124")
        @li
          Slightly improve hygiene of uPickle/PPrint macro expansion
        @li
          uPickle de-serialization failures should no longer throw @code{MatchErrors} (#101)
        @li
          Using case-class-derived @code{Reader}s/@code{Writer}s should no longer fail in class @code{extends} clauses (#108)
        @li
          @code{Float.NaN} and @code{Double.NaN} are now properly handled (#123)
        @li
          Provided an example of a @sect.ref{Custom Configuration} being used to @code{snake_case} case-class fields during serialization/de-serialization (#120)

    @sect{0.3.6}
      @ul
        @li
          Fix more bugs in PPrint derivation
    @sect{0.3.5}
      @ul
        @li
          Fix some bugs in PPrint derivation
    @sect{0.3.4}
      @ul
        @li
          Remove unnecessary shapeless dependency
    @sect{0.3.3}
      @ul
        @li
          Fix more edge cases to avoid diverging implicits
    @sect{0.3.2}
      @ul
        @li
          Fix more edge cases around typeclass derivation: #94, #95, #96
        @li
          Don't get tripped up by custom Apply methods: #48
    @sect{0.3.1}
      @ul
        @li
          Fixed edge cases around typeclass derivation

    @sect{0.3.0}
      @ul
        @li
          Top-to-bottom rewrite of type-class derivation macros. Much faster, more reliable, etc.. Still one or two cases where it misbehaves, but much fewer than before. Extracted it into the @hl.scala{derive} subproject
        @li
          Force users to choose between @hl.scala{import upickle.default._} which now renders sealed trait hierarchies as dictionaries with a @hl.scala{$type} attribute, and @hl.scala{import upickle.legacy._} which does the old-style array-wrapper.
        @li
          You can also now create your own custom subclass of @hl.scala{upickle.Api} if you wish to customize things further, e.g. changing the type-attribute or changing the rendering of case classes.

    @sect{0.2.8}
      @ul
        @li
          Support for @hl.scala{java.util.UUID}, which are serialized as strings in the standard format

    @sect{0.2.7}
      @ul
        @li
          Re-published for Scala.js 0.6.1

    @sect{0.2.6}
      @ul
        @li
          @hl.scala{'Symbol}s are now read/write-able by default
        @li
          Added lots of warnings for common issues
        @li
          @hl.scala{Map[String, V]} now pickles to a JSON dictionary @hl.scala(""""key": "value", ...}"""). @hl.scala{Map[K, V]} for all other @hl.scala{K != String} are unchanged
        @li
          Source maps now point towards a reasonabel place on Github


    @sect{0.2.5}
      @ul
        @li
          Fixed [#23](https://github.com/lihaoyi/upickle/issues/23): self-recursive data structures are now supported.
        @li
          Fixed [#18](https://github.com/lihaoyi/upickle/issues/18): you can now auto-pickle classes in objects that originated from traits that were mixed in.


    @sect{0.2.4}
      @ul
        @li
          Support reading and writing @hl.scala{null}
        @li
          Fixed Reader/Writer macros for single-class sealed hierarchies
        @li
          Used @hl.scala{CanBuildFrom} to serialize a broader range of collections

    @sect{0.2.3}
      @ul
        @li
          Added a pickler for @hl.scala{Unit}/@hl.scala{()}

    @sect{0.2.2}
      @ul
        @li
          Swapped over from the hand-rolled parser to using @hl.scala{Jawn}/@hl.scala{JSON.parse} on the two platforms, resulting in a 10-15x speedup for JSON handling.
        @li
          Renamed @hl.scala("""Js.{String, Object, Array, Number}""") into @hl.scala("""Js.{Str, Obj, Arr, Num}"""), and made @hl.scala{Js.Arr} and @hl.scala{Js.Obj} use varargs, to allow for better direct-use.
        @li
          Documented and exposed JSON API for direct use by users of the library.

    @sect{0.2.1}
      @ul
        @li
          Improved error messages for unpickle-able types
        @li
          ScalaJS version now built against 0.5.3

    @sect{0.2.0}
      @ul
        @li
          Members of sealed trait/class hierarchies are now keyed with the fully-qualified name of their class, rather than an index, as it is less likely to change due to adding or removing classes
        @li
          Members of sealed hierarchies and parameters now support a @hl.scala{upickle.key("...")} annotation, which allows you to override the default key used (which is the class/parameter name) with a custom one, allowing you to change the class/param name in your code while maintaining compatibility with serialized structures
        @li
          Default parameters are now supported: they are used to substitute missing keys when reading, and cause the key/value pair to be omitted if the serialized value matches the default when writing
        @li
          Missing keys when deserializing case classes now throws a proper @hl.scala{Invalid.Data} exception
        @li
          @hl.scala{object}s are now serialized as @hl.scala("""{}""") rather than @hl.scala{[]}, better matching the style of case classes
        @li
          0-argument case classes, previously unsupported, now serialize to @hl.scala("""{}""") the same way as @hl.scala{object}s
        @li
          Fixed a bug that was preventing multi-level sealed class hierarchies from being serialized due to a compilation error
        @li
         Fixed a bug causing case classes nested in other packages/objects and referred to by their qualified paths to fail pickling
        @li
          Tightened up error handling semantics, swapping out several @hl.scala{MatchError}s with @hl.scala{Invalid.Data} errors

    @sect{0.1.7}
      @ul
        @li
          Cleaned up the external API, marking lots of things which should have been private private or stuffing them in the @hl.scala{Internals} namespace
        @li
          Organized things such that only a single import @hl.scala{import upickle._} is necessary to use the library

    @sect{0.1.6}
      @ul
        @li
          Tuples and case classes now have implicit picklers up to an arity limit of 22.
        @li
          Case classes now serialize as JSON dictionaries rather than as lists.

    @sect{0.1.5}
      @ul
        @li
          Simple case classes and case class hierarchies are now auto-serializable view Macros. No need to define your own implicit using @hl.scala{Case0ReadWriter} anymore!

    @sect{0.1.4}
      @ul
        @li
          Serialize numbers as JSON numbers instead of Strings.

    @sect{0.1.3}
      @ul
        @li

          Specification of the exception-throwing behavior: instead of failing with random @hl.scala{MatchError}s or similar, parse failures now are restricted to subclasses @hl.scala{upickle.Invalid} which define different failure modes.
